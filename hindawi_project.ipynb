{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-25T12:43:06.11047Z",
          "iopub.status.busy": "2025-11-25T12:43:06.110247Z",
          "iopub.status.idle": "2025-11-25T12:43:07.849308Z",
          "shell.execute_reply": "2025-11-25T12:43:07.848551Z",
          "shell.execute_reply.started": "2025-11-25T12:43:06.110442Z"
        },
        "id": "W9-0rIDVR5Qy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:37:47.958337Z",
          "iopub.status.busy": "2025-11-26T09:37:47.957756Z",
          "iopub.status.idle": "2025-11-26T09:38:00.960046Z",
          "shell.execute_reply": "2025-11-26T09:38:00.95906Z",
          "shell.execute_reply.started": "2025-11-26T09:37:47.95831Z"
        },
        "id": "i8WoLm9JR5Q0",
        "outputId": "f0e0a157-e376-4219-c47c-7225ee7ee0be",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.52.4\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.2.0)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2025.3.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2022.3.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2025.10.5)\n",
            "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2025.3.0)\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2022.3.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.52.4) (1.4.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.52.4) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\n",
            "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.3\n",
            "    Uninstalling transformers-4.53.3:\n",
            "      Successfully uninstalled transformers-4.53.3\n",
            "Successfully installed transformers-4.52.4\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.52.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "946194ef894344608c83121df41e90d2"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-11-26T09:38:34.904104Z",
          "iopub.status.busy": "2025-11-26T09:38:34.903795Z",
          "iopub.status.idle": "2025-11-26T09:38:34.918931Z",
          "shell.execute_reply": "2025-11-26T09:38:34.918134Z",
          "shell.execute_reply.started": "2025-11-26T09:38:34.90408Z"
        },
        "id": "KAuLU2q6R5Q1",
        "outputId": "a7d274f8-f002-416e-d0b4-bfaef0ee9340",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "946194ef894344608c83121df41e90d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUsMX-t8R5Q2"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "73e326ff823d4a528a76276caa84b1e6",
            "75a7ca4204954c2ea4bd9a9cbb5ecaa8",
            "3bf3acb4d21b4eff989b015702f08e56",
            "3e3728b1bcce46f1acb823add2bf1fb0",
            "a3d2280ed8ea4e84a2304acd0daa820d",
            "ff46f4cb2fdc46ccab216f19c8ef6e63",
            "c4ce47946d33444eab49cdf72e69a620",
            "09f62aa005dc4002b9f3e8a1b07e5cf6",
            "0a40547c8f4040d69c3515bfedc241b5",
            "db3cf33c2b6c4d098207e9c69235d6aa",
            "3124671eb9d248a9bda5986849b4c375",
            "ee22373017fa475a83416c445386e485",
            "7678538176fa4cdebc7722591a76aff7"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-11-26T09:40:20.53935Z",
          "iopub.status.busy": "2025-11-26T09:40:20.538755Z",
          "iopub.status.idle": "2025-11-26T09:43:39.510458Z",
          "shell.execute_reply": "2025-11-26T09:43:39.509796Z",
          "shell.execute_reply.started": "2025-11-26T09:40:20.53932Z"
        },
        "id": "XGLWuN0mR5Q3",
        "outputId": "2a336d6a-396b-4c35-cd41-88efb86c659a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73e326ff823d4a528a76276caa84b1e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a7ca4204954c2ea4bd9a9cbb5ecaa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bf3acb4d21b4eff989b015702f08e56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e3728b1bcce46f1acb823add2bf1fb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-26 09:40:36.822647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764150036.990212      46 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764150037.037542      46 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3d2280ed8ea4e84a2304acd0daa820d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff46f4cb2fdc46ccab216f19c8ef6e63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4ce47946d33444eab49cdf72e69a620",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09f62aa005dc4002b9f3e8a1b07e5cf6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a40547c8f4040d69c3515bfedc241b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db3cf33c2b6c4d098207e9c69235d6aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3124671eb9d248a9bda5986849b4c375",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee22373017fa475a83416c445386e485",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7678538176fa4cdebc7722591a76aff7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def generate_text(prompt, max_length=1000, num_return_sequences=1):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        do_sample=False,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:44:12.181946Z",
          "iopub.status.busy": "2025-11-26T09:44:12.181269Z",
          "iopub.status.idle": "2025-11-26T09:44:12.189298Z",
          "shell.execute_reply": "2025-11-26T09:44:12.188437Z",
          "shell.execute_reply.started": "2025-11-26T09:44:12.181919Z"
        },
        "id": "xuXpEKZAR5Q4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from langchain.llms.base import LLM\n",
        "from typing import Any\n",
        "\n",
        "class CustomHFLLM(LLM):\n",
        "    def _call(self, prompt: str, stop: Any = None) -> str:\n",
        "        return generate_text(prompt, max_length=500)\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom_huggingface\"\n",
        "\n",
        "llm = CustomHFLLM()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkW_NVwR5Q4"
      },
      "source": [
        "# Classification Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:51:23.018875Z",
          "iopub.status.busy": "2025-11-26T09:51:23.018135Z",
          "iopub.status.idle": "2025-11-26T09:51:23.195204Z",
          "shell.execute_reply": "2025-11-26T09:51:23.194421Z",
          "shell.execute_reply.started": "2025-11-26T09:51:23.018845Z"
        },
        "id": "jgNYJ6FaR5Q4",
        "outputId": "0d57d864-70de-4a87-d159-ca408a2863d9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_46/365848651.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  classify_chain = LLMChain(\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "# Chain 1: Task Classification\n",
        "classify_prompt = PromptTemplate(\n",
        "    input_variables=[\"tasks\"],\n",
        "    template=(\n",
        "        \"Classify the following tasks into categories: Urgent, Normal, Optional.\\n\\n\"\n",
        "        \"Tasks:\\n{tasks}\\n\\n\"\n",
        "        \"Respond ONLY in JSON like this:\\n\"\n",
        "        \"{{\\n  \\\"Urgent\\\": [],\\n  \\\"Normal\\\": [],\\n  \\\"Optional\\\": []\\n}}\\n\"\n",
        "    )\n",
        ")\n",
        "\n",
        "classify_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=classify_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:51:34.22789Z",
          "iopub.status.busy": "2025-11-26T09:51:34.227585Z",
          "iopub.status.idle": "2025-11-26T09:51:34.233959Z",
          "shell.execute_reply": "2025-11-26T09:51:34.233081Z",
          "shell.execute_reply.started": "2025-11-26T09:51:34.227868Z"
        },
        "id": "yYCiMPTOR5Q5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "def extract_json_classify(classify):\n",
        "    match = re.search(r\"```json\\s*(\\{[\\s\\S]*?\\})\\s*```\", classify)\n",
        "    if match:\n",
        "        json_str = match.group(1)\n",
        "    else:\n",
        "        # fallback: extract the last {...} block\n",
        "        json_candidates = re.findall(r\"\\{[\\s\\S]*?\\}\", classify)\n",
        "        json_str = json_candidates[-1]\n",
        "\n",
        "    # Convert string → dict\n",
        "    classified_tasks_dict = json.loads(json_str)\n",
        "\n",
        "    # Convert dict → clean JSON text\n",
        "    classified_tasks = json.dumps(classified_tasks_dict)\n",
        "    return classified_tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq8J214LR5Q6"
      },
      "source": [
        "# Plan chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:51:59.18025Z",
          "iopub.status.busy": "2025-11-26T09:51:59.17953Z",
          "iopub.status.idle": "2025-11-26T09:51:59.185314Z",
          "shell.execute_reply": "2025-11-26T09:51:59.184433Z",
          "shell.execute_reply.started": "2025-11-26T09:51:59.18021Z"
        },
        "id": "goSFPDhQR5Q6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "# Chain 2: Daily Plan\n",
        "plan_prompt = PromptTemplate(\n",
        "    input_variables=[\"classified_tasks\"],\n",
        "    template=(\n",
        "        \"You are given classified tasks in JSON:\\n\"\n",
        "        \"{classified_tasks}\\n\\n\"\n",
        "        \"Create a daily plan using ONLY tasks from the input (10 tasks total).\\n\"\n",
        "        \"Distribute them into three periods: Morning, Afternoon, Evening.\\n\"\n",
        "        \"***Each period must contain 3–4 tasks to ensure all tasks are included.***\\n\\n\" # MODIFIED CONSTRAINT\n",
        "        \"Respond ONLY in JSON like this:\\n\"\n",
        "        \"{{\\n\"\n",
        "        \"  \\\"Morning\\\": [],\\n\"\n",
        "        \"  \\\"Afternoon\\\": [],\\n\"\n",
        "        \"  \\\"Evening\\\": []\\n\"\n",
        "        \"}}\\n\"\n",
        "    )\n",
        ")\n",
        "\n",
        "plan_chain = LLMChain(\n",
        "    llm=llm, # 'llm' must be an instantiated Language Model object\n",
        "    prompt=plan_prompt,\n",
        ")\n",
        "\n",
        "#plan = plan_chain.run({\"classified_tasks\": classified_tasks})\n",
        "\n",
        "#print(f\"\\nFeatures:\\n{plan.strip()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:52:10.108327Z",
          "iopub.status.busy": "2025-11-26T09:52:10.108016Z",
          "iopub.status.idle": "2025-11-26T09:52:10.113871Z",
          "shell.execute_reply": "2025-11-26T09:52:10.1131Z",
          "shell.execute_reply.started": "2025-11-26T09:52:10.108304Z"
        },
        "id": "D5r-To2OR5Q7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def extract_json_plan(plan):\n",
        "    match = re.search(\n",
        "    r'\\{[\\s\\S]*\"Evening\":\\s*\\[[\\s\\S]*?\\][\\s\\S]*\\}',\n",
        "    plan,\n",
        "    re.DOTALL | re.IGNORECASE )\n",
        "\n",
        "    plan_dict = None\n",
        "    plan_json_str = None\n",
        "    if match:\n",
        "\n",
        "        all_json_matches = re.findall(r'(\\{[^}]+\\})', plan, re.DOTALL)\n",
        "\n",
        "        if all_json_matches:\n",
        "            plan_json_str = all_json_matches[-1]\n",
        "            try:\n",
        "                # Clean the string (remove excessive whitespace/newlines)\n",
        "                plan_json_str = re.sub(r'\\s+', ' ', plan_json_str).strip()\n",
        "                # Load the cleaned string into a Python dictionary\n",
        "                plan_dict = json.loads(plan_json_str)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error: Extracted text is not valid JSON. {e}\")\n",
        "                print(f\"Bad string: {plan_json_str}\")\n",
        "                plan_dict = None\n",
        "        else:\n",
        "            print(\"Error: No JSON dictionary found in LLM output.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Error: No JSON structure found in LLM output.\")\n",
        "    return plan_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH4GbtIVR5Q7"
      },
      "source": [
        "# advice chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:52:24.914892Z",
          "iopub.status.busy": "2025-11-26T09:52:24.914138Z",
          "iopub.status.idle": "2025-11-26T09:52:24.918641Z",
          "shell.execute_reply": "2025-11-26T09:52:24.918068Z",
          "shell.execute_reply.started": "2025-11-26T09:52:24.914864Z"
        },
        "id": "HcvOXG2UR5Q7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "advice_prompt = PromptTemplate(\n",
        "    input_variables=[\"classified_tasks\"],\n",
        "    template=(\n",
        "        \"You are given today's tasks in JSON:\\n\"\n",
        "        \"{classified_tasks}\\n\\n\"\n",
        "        \"Provide 3 practical productivity tips based ONLY on these tasks.\\n\\n\"\n",
        "        \"Respond ONLY in JSON like this:\\n\"\n",
        "        \"{{\\n\"\n",
        "        \"  \\\"tips\\\": [\\n\"\n",
        "        \"    \\\"Tip 1...\\\",\\n\"\n",
        "        \"    \\\"Tip 2...\\\",\\n\"\n",
        "        \"    \\\"Tip 3...\\\"\\n\"\n",
        "        \"  ]\\n\"\n",
        "        \"}}\\n\"\n",
        "    )\n",
        ")\n",
        "advice_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=advice_prompt,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T09:52:35.47435Z",
          "iopub.status.busy": "2025-11-26T09:52:35.473592Z",
          "iopub.status.idle": "2025-11-26T09:52:35.47955Z",
          "shell.execute_reply": "2025-11-26T09:52:35.478868Z",
          "shell.execute_reply.started": "2025-11-26T09:52:35.474321Z"
        },
        "id": "dm_17uWxR5Q7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def extract_json_advice(advice):\n",
        "    match = re.search(\n",
        "    r'\\{*\"tips\":\\s*\\[[\\s\\S]*?\\][\\s\\S]*\\}',\n",
        "    advice,\n",
        "    re.DOTALL | re.IGNORECASE )\n",
        "    tips_dict = None\n",
        "    tips_json_str = None\n",
        "    if match:\n",
        "        all_json_matches = re.findall(r'(\\{[^}]+\\})', advice, re.DOTALL)\n",
        "\n",
        "        if all_json_matches:\n",
        "            # Take the last JSON block found, as that is the final plan\n",
        "            tips_json_str = all_json_matches[-1]\n",
        "            try:\n",
        "                # Clean the string (remove excessive whitespace/newlines)\n",
        "                tips_json_str = re.sub(r'\\s+', ' ', tips_json_str).strip()\n",
        "                # Load the cleaned string into a Python dictionary\n",
        "                tips_dict = json.loads(tips_json_str)\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error: Extracted text is not valid JSON. {e}\")\n",
        "                print(f\"Bad string: {tips_json_str}\")\n",
        "                tips_dict = None\n",
        "        else:\n",
        "            print(\"Error: No JSON dictionary found in LLM output.\")\n",
        "    else:\n",
        "        print(\"Error: No JSON structure found in LLM output.\")\n",
        "    return tips_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T8682hvR5Q8"
      },
      "source": [
        "# example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T10:51:59.89512Z",
          "iopub.status.busy": "2025-11-26T10:51:59.894444Z",
          "iopub.status.idle": "2025-11-26T10:51:59.898261Z",
          "shell.execute_reply": "2025-11-26T10:51:59.89756Z",
          "shell.execute_reply.started": "2025-11-26T10:51:59.895091Z"
        },
        "id": "Mpg9EB58R5Q8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "task = \"\"\"\n",
        "- Finish Python assignment\n",
        "- Clean the room\n",
        "- Buy groceries\n",
        "- Watch a tutorial\n",
        "- Call mom\n",
        "- Water the plants\n",
        "- Exercise for 30 minutes\n",
        "- Read a chapter of a book\n",
        "- Organize desk\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T10:52:03.131205Z",
          "iopub.status.busy": "2025-11-26T10:52:03.130923Z",
          "iopub.status.idle": "2025-11-26T11:03:02.319864Z",
          "shell.execute_reply": "2025-11-26T11:03:02.319037Z",
          "shell.execute_reply.started": "2025-11-26T10:52:03.131183Z"
        },
        "id": "fJEZj-jPR5Q8",
        "outputId": "1f6feada-8484-4edd-b8e5-a8b6883146ce",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "classify_out = classify_chain.run({\"tasks\": task})\n",
        "classified_json = extract_json_classify(classify_out)\n",
        "\n",
        "\n",
        "plan_out = plan_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "plan_json = extract_json_plan(plan_out)\n",
        "\n",
        "\n",
        "advice_out = advice_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "advice_json = extract_json_advice(advice_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T11:03:14.851218Z",
          "iopub.status.busy": "2025-11-26T11:03:14.85048Z",
          "iopub.status.idle": "2025-11-26T11:03:14.855181Z",
          "shell.execute_reply": "2025-11-26T11:03:14.854501Z",
          "shell.execute_reply.started": "2025-11-26T11:03:14.85119Z"
        },
        "id": "2egsyik6R5Q9",
        "outputId": "da3ae321-0ef8-4a2a-eada-b7258220d9e4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"Urgent\": [\"Finish Python assignment\", \"Call mom\"], \"Normal\": [\"Clean the room\", \"Buy groceries\", \"Water the plants\", \"Organize desk\"], \"Optional\": [\"Watch a tutorial\", \"Exercise for 30 minutes\", \"Read a chapter of a book\"]}\n",
            "====================\n",
            "{'Morning': ['Finish Python assignment', 'Call mom', 'Clean the room'], 'Afternoon': ['Buy groceries', 'Water the plants', 'Organize desk'], 'Evening': ['Watch a tutorial', 'Exercise for 30 minutes', 'Read a chapter of a book']}\n",
            "====================\n",
            "{'tips': [\"Prioritize tasks from the 'Urgent' category first, as they require immediate attention.\", \"Break down larger tasks like 'Clean the room' or 'Organize desk' into smaller, manageable steps to make them less overwhelming.\", \"Use the 'Optional' tasks as rewards for completing tasks from the 'Urgent' and 'Normal' categories to maintain motivation and productivity.\"]}\n"
          ]
        }
      ],
      "source": [
        "print(classified_json)\n",
        "print(\"====================\")\n",
        "print(plan_json)\n",
        "print(\"====================\")\n",
        "print(advice_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz8tSm2xR5Q9",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P58iDRIKR5Q9"
      },
      "source": [
        "# example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T11:51:51.057737Z",
          "iopub.status.busy": "2025-11-26T11:51:51.057429Z"
        },
        "id": "A0jBk9SIR5Q9",
        "outputId": "ed0af49d-6b43-43ed-9f96-28238398d7eb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "task2 = \"\"\"\n",
        "- Review machine learning lesson\n",
        "- Update your project notes\n",
        "- Prepare a healthy meal\n",
        "- Respond to important emails\n",
        "- Take a 20-minute walk\n",
        "- Backup important files\n",
        "- Practice English speaking\n",
        "- Meditate for 10 minutes\n",
        "\"\"\"\n",
        "classify_out = classify_chain.run({\"tasks\": task2})\n",
        "classified_json = extract_json_classify(classify_out)\n",
        "\n",
        "\n",
        "plan_out = plan_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "plan_json = extract_json_plan(plan_out)\n",
        "\n",
        "\n",
        "advice_out = advice_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "advice_json = extract_json_advice(advice_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T11:51:33.185774Z",
          "iopub.status.busy": "2025-11-26T11:51:33.185191Z",
          "iopub.status.idle": "2025-11-26T11:51:33.189709Z",
          "shell.execute_reply": "2025-11-26T11:51:33.188846Z",
          "shell.execute_reply.started": "2025-11-26T11:51:33.185746Z"
        },
        "id": "iuoOTH3hR5Q-",
        "outputId": "6a2f3c3d-6e67-40ec-bd63-197773527515",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"Urgent\": [\"Respond to important emails\", \"Backup important files\"], \"Normal\": [\"Review machine learning lesson\", \"Update your project notes\", \"Prepare a healthy meal\", \"Plan tomorrow\\u2019s tasks\"], \"Optional\": [\"Take a 20-minute walk\", \"Practice English speaking\", \"Meditate for 10 minutes\"]}\n"
          ]
        }
      ],
      "source": [
        "print(classified_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrnxDoF8R5Q-"
      },
      "source": [
        "# example 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T11:18:41.220802Z",
          "iopub.status.busy": "2025-11-26T11:18:41.220166Z",
          "iopub.status.idle": "2025-11-26T11:30:32.883643Z",
          "shell.execute_reply": "2025-11-26T11:30:32.882958Z",
          "shell.execute_reply.started": "2025-11-26T11:18:41.220776Z"
        },
        "id": "yW1m9dgVR5Q-",
        "outputId": "a52b4672-cf4a-46e5-f145-2a125c6db31f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "task3 = \"\"\"\n",
        "- Sort study materials\n",
        "- Review last lecture notes\n",
        "- Prepare weekly budget\n",
        "- Charge all devices\n",
        "- Check upcoming deadlines\n",
        "- Practice coding for 1 hour\n",
        "- Declutter phone gallery\n",
        "- Drink 2 cups of water\n",
        "- Set goals for the week\n",
        "\"\"\"\n",
        "classify_out = classify_chain.run({\"tasks\": task3})\n",
        "classified_json = extract_json_classify(classify_out)\n",
        "\n",
        "\n",
        "plan_out = plan_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "plan_json = extract_json_plan(plan_out)\n",
        "\n",
        "\n",
        "advice_out = advice_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "advice_json = extract_json_advice(advice_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-26T11:35:25.080471Z",
          "iopub.status.busy": "2025-11-26T11:35:25.079743Z",
          "iopub.status.idle": "2025-11-26T11:35:25.084786Z",
          "shell.execute_reply": "2025-11-26T11:35:25.084052Z",
          "shell.execute_reply.started": "2025-11-26T11:35:25.080446Z"
        },
        "id": "UDdZ8NP0R5Q_",
        "outputId": "a212cc88-2402-480f-d68f-1e68dc329823",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"Urgent\": [\"Check upcoming deadlines\"], \"Normal\": [\"Sort study materials\", \"Review last lecture notes\", \"Prepare weekly budget\", \"Charge all devices\", \"Practice coding for 1 hour\", \"Set goals for the week\"], \"Optional\": [\"Declutter phone gallery\", \"Drink 2 cups of water\"]}\n",
            "====================\n",
            "{'Morning': ['Check upcoming deadlines', 'Sort study materials', 'Review last lecture notes'], 'Afternoon': ['Prepare weekly budget', 'Charge all devices', 'Practice coding for 1 hour'], 'Evening': ['Set goals for the week', 'Declutter phone gallery', 'Drink 2 cups of water']}\n",
            "====================\n",
            "{'tips': [\"Prioritize tasks by urgency and importance. Start with 'Check upcoming deadlines' under 'Urgent' tasks.\", \"Break down larger tasks into smaller, manageable steps. For example, 'Sort study materials' can be done category by category.\", \"Use reminders or alarms to ensure you complete tasks on time. Set a reminder for 'Prepare weekly budget' to ensure it's done before the week starts.\"]}\n"
          ]
        }
      ],
      "source": [
        "print(classified_json)\n",
        "print(\"====================\")\n",
        "print(plan_json)\n",
        "print(\"====================\")\n",
        "print(advice_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbO8SLo0R5Q_",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-25T17:33:51.739993Z",
          "iopub.status.busy": "2025-11-25T17:33:51.739513Z",
          "iopub.status.idle": "2025-11-25T17:33:55.391552Z",
          "shell.execute_reply": "2025-11-25T17:33:55.390816Z",
          "shell.execute_reply.started": "2025-11-25T17:33:51.73997Z"
        },
        "id": "nGRN5VM_R5Q_",
        "outputId": "1a8cb1db-7f47-4555-bf1c-039491e91b54",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.5.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.47.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.12.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn pyngrok nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-25T17:34:06.114297Z",
          "iopub.status.busy": "2025-11-25T17:34:06.113975Z",
          "iopub.status.idle": "2025-11-25T17:34:06.118451Z",
          "shell.execute_reply": "2025-11-25T17:34:06.117648Z",
          "shell.execute_reply.started": "2025-11-25T17:34:06.114263Z"
        },
        "id": "G8AfbtPkR5RA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "NGROK_TOKEN = \" \" \n",
        "API_KEY = \"secret12345\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-25T17:34:08.991548Z",
          "iopub.status.busy": "2025-11-25T17:34:08.99096Z",
          "iopub.status.idle": "2025-11-25T17:34:08.998061Z",
          "shell.execute_reply": "2025-11-25T17:34:08.997231Z",
          "shell.execute_reply.started": "2025-11-25T17:34:08.991526Z"
        },
        "id": "zMJvlZVIR5RA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, Request, HTTPException\n",
        "import uvicorn, threading, time, socket\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "app = FastAPI()\n",
        "@app.post(\"/test\")\n",
        "async def chat(req: Request):\n",
        "    if req.headers.get(\"authorization\") != f\"Bearer {API_KEY}\":\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "\n",
        "    data = await req.json()\n",
        "    tasks = data.get(\"tasks\")\n",
        "\n",
        "    classify_out = classify_chain.run({\"tasks\": tasks})\n",
        "    classified_json = extract_json_classify(classify_out)\n",
        "\n",
        "    # ---- 2) Plan ----\n",
        "    plan_out = plan_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "    plan_json = extract_json_plan(plan_out)\n",
        "\n",
        "    # ---- 3) Advice ----\n",
        "    advice_out = advice_chain.run({\"classified_tasks\": json.dumps(classified_json)})\n",
        "    advice_json = extract_json_advice(advice_out)\n",
        "\n",
        "    # ---- Final Response ----\n",
        "    return {\n",
        "        \"classified\": classified_json,\n",
        "        \"plan\": plan_json,\n",
        "        \"advice\": advice_json\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-25T17:35:08.574528Z",
          "iopub.status.busy": "2025-11-25T17:35:08.574262Z",
          "iopub.status.idle": "2025-11-25T17:35:09.839752Z",
          "shell.execute_reply": "2025-11-25T17:35:09.839163Z",
          "shell.execute_reply.started": "2025-11-25T17:35:08.574508Z"
        },
        "id": "SwZg7SSOR5RA",
        "outputId": "4b11c55c-b35d-4901-fced-8a9e2df9a321",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your public URL: https://nigel-placid-anabelle.ngrok-free.dev\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [47]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:34321 (Press CTRL+C to quit)\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "def free_port():\n",
        "    s = socket.socket()\n",
        "    s.bind(('', 0))\n",
        "    port = s.getsockname()[1]\n",
        "    s.close()\n",
        "    return port\n",
        "\n",
        "port = free_port()\n",
        "conf.get_default().auth_token = NGROK_TOKEN\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\"Your public URL:\", public_url)\n",
        "\n",
        "def run(): uvicorn.run(app, host=\"0.0.0.0\", port=port)\n",
        "threading.Thread(target=run, daemon=True).start()\n",
        "time.sleep(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "hindawi project",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
